{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7kZbEWehmr8CB3Rk52Wrw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazlicodes/ADNOC_NLP_QuestionAndAnswering_System/blob/main/BardAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializations"
      ],
      "metadata": {
        "id": "BWGoG_ZLMiEi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8204O_elLFi"
      },
      "outputs": [],
      "source": [
        "pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "%env OPENAI_API_KEY= #Your API Key\n",
        "import pandas as pd\n",
        "import openai"
      ],
      "metadata": {
        "id": "W4dwtjoJE2Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import google.generativeai as palm\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rygEEr56lbwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DJlvIb-1noxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palm.configure(api_key=) #your API key"
      ],
      "metadata": {
        "id": "gNHcCk97ldeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
        "model = models[0].name\n",
        "print(model)"
      ],
      "metadata": {
        "id": "2WZ-cSH-lllN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q&A Generation"
      ],
      "metadata": {
        "id": "Z8P7YFlAM312"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/clean_context_gpt3_5.csv')\n"
      ],
      "metadata": {
        "id": "7n_dXvdHsVsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_questions(context, temp=0):\n",
        "    try:\n",
        "        prompt = f\"in different question styles (how, where, when, etc.) Write 30 of informative questions (without answers) based on the drill report below\\n\\nText: {context}\\n\\nQuestions:\\n1.\"\n",
        "        completion = palm.generate_text(\n",
        "            model=model,\n",
        "            prompt=prompt,\n",
        "            temperature=temp,\n",
        "            # The maximum length of the response\n",
        "            max_output_tokens=4000,\n",
        "        )\n",
        "        return completion.result\n",
        "    except:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "N-zO2R6hoO3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['questions2']= df['clean_gpt3.5'].apply(get_questions, temp=1)\n",
        "df['questions2'] = \"1.\" + df.questions2\n",
        "print(df[['questions2']].values[0][0])"
      ],
      "metadata": {
        "id": "BWPUcShplpSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answers(df, temp=0):\n",
        "    try:\n",
        "        prompt=f\"Write the answer of the following questions based on the drill report below\\n\\nText: {df.clean_gpt}\\n\\nQuestions:\\n{df.questions2}\\n\\nAnswers:\\n1.\"\n",
        "        completion = palm.generate_text(\n",
        "            model=model,\n",
        "            prompt=prompt,\n",
        "            temperature=temp,\n",
        "            # The maximum length of the response\n",
        "            max_output_tokens=4000,\n",
        "        )\n",
        "        return completion.result\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "e372uX62pBYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"clean_gpt\"] = df[\"clean_gpt3.5\"]"
      ],
      "metadata": {
        "id": "C-P7qNNCx5yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['answers2']= df.apply(get_answers, axis=1, temp=0)"
      ],
      "metadata": {
        "id": "AD9sddYmpsse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:,[\"clean_gpt\",\"questions2\",\"answers2\"]].to_csv('/content/q&a_exp6_temp1_cleancontext.csv', index=False)"
      ],
      "metadata": {
        "id": "Y_zyo0XVyJ6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_answers(\"what was going on at hour 21:00? and what does that mean?\",context, temp = 0))"
      ],
      "metadata": {
        "id": "fuFqALd8qh7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question filtering"
      ],
      "metadata": {
        "id": "NCwliC1JNBpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasketch\n"
      ],
      "metadata": {
        "id": "DaZddMJGV4t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "gTNtdUcOg_EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/q&a_exp6_temp1_cleancontext.csv')\n",
        "questions_combined = '\\n'.join(df['questions2'].dropna())"
      ],
      "metadata": {
        "id": "QkFfgkqr5Y-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qList = questions_combined.splitlines()\n",
        "\n",
        "# If the index is separated by a space:\n",
        "qList = [question.split('. ', 1)[1] if '. ' in question else question.split('.', 1)[1] for question in qList]\n",
        "qList = list(set(qList))\n"
      ],
      "metadata": {
        "id": "d3evtVH26Fvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasketch import MinHash, MinHashLSH\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords_list = set(stopwords.words('english'))\n",
        "\n",
        "additional_stopwords = {\"is\", \"the\", \"what\", \"are\", \"how\"}\n",
        "stopwords_list.update(additional_stopwords)\n",
        "\n",
        "def compute_minhash(text):\n",
        "    m = MinHash(num_perm=128)\n",
        "    for word in text.split():\n",
        "        if word.lower() not in stopwords_list:\n",
        "            m.update(word.encode('utf8'))\n",
        "    return m\n",
        "\n",
        "# Compute MinHash for each question\n",
        "minhashes = [(i, compute_minhash(question)) for i, question in enumerate(qList)]\n",
        "\n",
        "# Create LSH index\n",
        "lsh = MinHashLSH(threshold=0.7, num_perm=128)\n",
        "for idx, minhash in minhashes:\n",
        "    lsh.insert(str(idx), minhash)\n",
        "\n",
        "# Find groups of similar questions\n",
        "similar_question_groups = []\n",
        "seen = set()\n",
        "for idx, minhash in minhashes:\n",
        "    if str(idx) not in seen:\n",
        "        similar_questions = lsh.query(minhash)\n",
        "        similar_questions = [q for q in similar_questions if q not in seen]\n",
        "        seen.update(similar_questions)\n",
        "        similar_question_groups.append(similar_questions)\n"
      ],
      "metadata": {
        "id": "J6Y77N3gVy-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isSimilar(Q1,Q2):\n",
        "  prompt = f\"does these two questions have the same meaning: \\n Q1 \\n {Q1} \\n Q2 \\n {Q2}?\"\n",
        "  completion = palm.generate_text(\n",
        "      model=model,\n",
        "      prompt=prompt,\n",
        "      temperature=0,\n",
        "      # The maximum length of the response\n",
        "      max_output_tokens=400,\n",
        "  )\n",
        "  if completion.result.lower() == \"yes\":\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "XaOQiii06bl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def saveQuestionsToFile(questions, filename):\n",
        "    with open(filename, \"w\") as f:\n",
        "        for question in questions:\n",
        "            f.write(question + \"\\n\")\n",
        "\n",
        "def loadQuestionsFromFile(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        questions = f.read().splitlines()\n",
        "    return questions\n",
        "\n",
        "\n",
        "#/content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "9XQqcPrynqAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isSimilar2(Q1,Q2):\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-16k-0613\",\n",
        "    messages=[{ \"role\": \"system\", \"content\": \"You are a similarity detector, if two questions are similar you print 'yes' and if they are different you print 'no'.\" },{\"role\": \"user\", \"content\": f\"does these two questions have the same meaning: \\n Q1 \\n {Q1} \\n Q2 \\n {Q2}?\"}])\n",
        "  if response['choices'][0][\"message\"][\"content\"] == \"yes\":\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "SFFWQK44FDbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getUniqueQuestions(qList):\n",
        "    uniqueQuestions = set()\n",
        "    checkedPairs = set()\n",
        "\n",
        "    for i in range(len(qList)):\n",
        "        isUnique = True\n",
        "\n",
        "        for j in range(i+1, len(qList)):\n",
        "            # Skip pair if it's already been checked\n",
        "            if (i, j) in checkedPairs or (j, i) in checkedPairs:\n",
        "                continue\n",
        "\n",
        "            if isSimilar2(qList[i], qList[j]):\n",
        "                isUnique = False\n",
        "\n",
        "            checkedPairs.add((i, j))\n",
        "\n",
        "        if isUnique:\n",
        "            uniqueQuestions.add(qList[i])\n",
        "\n",
        "    return list(uniqueQuestions)\n"
      ],
      "metadata": {
        "id": "c7Q12WaP8VLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "#uniqueList = getUniqueQuestions(qList2)\n",
        "# Apply your unique question finding algorithm to similar question groups\n",
        "unique_questions = []\n",
        "for group in similar_question_groups:\n",
        "    group_questions = [qList[int(i)] for i in group]\n",
        "    print(group_questions)\n",
        "    unique_group_questions = getUniqueQuestions(group_questions)\n",
        "    unique_questions.extend(unique_group_questions)\n",
        "# Save questions to file\n",
        "saveQuestionsToFile(unique_questions, \"/content/drive/MyDrive/unique_questions2.txt\")"
      ],
      "metadata": {
        "id": "by4y1RMG8WfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the questions back from the file\n",
        "loaded_questions = loadQuestionsFromFile(\"/content/drive/MyDrive/unique_questions.txt\")"
      ],
      "metadata": {
        "id": "M1uleQQwok73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_questions"
      ],
      "metadata": {
        "id": "2HHUSwgNoxMN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}